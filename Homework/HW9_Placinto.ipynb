{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW9_Placinto.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"bFTzajnBhvJW","colab_type":"text"},"source":["Austin Placinto\n","I have neither given nor received any unauthorized aid in completing this work, nor have I presented someone else's work as my own."]},{"cell_type":"code","metadata":{"id":"4LpGRoZrkLwW","colab_type":"code","outputId":"1eb16361-ede2-4855-dafd-e43f8a73b59f","executionInfo":{"status":"ok","timestamp":1572470134473,"user_tz":240,"elapsed":2249,"user":{"displayName":"Austin Placinto","photoUrl":"","userId":"00158340154549366790"}},"colab":{"base_uri":"https://localhost:8080/","height":99}},"source":["import keras\n","keras.__version__"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["'2.2.5'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"dAToL0PLkKYQ","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-ZQm46dFnY6Y","colab_type":"text"},"source":["Initialize Directories"]},{"cell_type":"code","metadata":{"id":"N4LahkNEkPZf","colab_type":"code","colab":{}},"source":["# Directories\n","train_dir =      '/gdrive/My Drive/vcc19sm2/train'\n","validation_dir = '/gdrive/My Drive/vcc19sm2/validation'\n","test_dir =       '/gdrive/My Drive/vcc19sm2/test'\n","\n","train_circ_dir =      '/gdrive/My Drive/vcc19sm2/train/circle'\n","train_not_dir =      '/gdrive/My Drive/vcc19sm2/train/not_circle'\n","validation_circ_dir = '/gdrive/My Drive/vcc19sm2/validation/circle'\n","validation_not_dir = '/gdrive/My Drive/vcc19sm2/validation/not_circle'\n","test_circ_dir =       '/gdrive/My Drive/vcc19sm2/test/circle'\n","test_not_dir =       '/gdrive/My Drive/vcc19sm2/test/not_circle'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BmzQ2WkDnUJu","colab_type":"text"},"source":["Make sure the data has been read."]},{"cell_type":"code","metadata":{"id":"-MvSV6MJmuTt","colab_type":"code","colab":{}},"source":["import os, shutil\n","print('total training circle images:', len(os.listdir(train_circ_dir)))\n","print('total training non-circle images:', len(os.listdir(train_not_dir)))\n","print('total validation circle images:', len(os.listdir(validation_circ_dir)))\n","print('total validation non-circle images:', len(os.listdir(validation_not_dir)))\n","print('total test circle images:', len(os.listdir(test_circ_dir)))\n","print('total test non-circle images:', len(os.listdir(test_not_dir)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QoRa45QCndQq","colab_type":"text"},"source":["Pre-processing."]},{"cell_type":"code","metadata":{"id":"nd0fp5dZo5Fy","colab_type":"code","colab":{}},"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=0,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.1,\n","    zoom_range=0.2,\n","    #brightness_range=[1.2,1.5],\n","    horizontal_flip=True,)\n","\n","train_generator = train_datagen.flow_from_directory(     \n","        train_dir, # This is the target directory\n","        target_size=(150, 150), # All images will be resized to 150x150\n","        batch_size=10,\n","        # Since we use binary_crossentropy loss, we need binary labels\n","        class_mode='binary')\n","\n","# Note that the validation data should not be augmented!\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","validation_generator = test_datagen.flow_from_directory(\n","        validation_dir,\n","        target_size=(150, 150),\n","        batch_size=5,\n","        class_mode='binary')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"66IzLY8ynmW6","colab_type":"text"},"source":["Get shape"]},{"cell_type":"code","metadata":{"id":"5IRjaLmXngf8","colab_type":"code","colab":{}},"source":["for data_batch, labels_batch in train_generator:\n","    print('data batch shape:', data_batch.shape)\n","    print('labels batch shape:', labels_batch.shape)\n","    break"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cVYmlB6an4B0","colab_type":"text"},"source":["Build Model"]},{"cell_type":"code","metadata":{"id":"uUI0VsTVn5iT","colab_type":"code","colab":{}},"source":["from keras import layers\n","from keras import models\n","from keras import optimizers\n","\n","model = models.Sequential()\n","model.add(layers.Conv2D(32, (3, 3), activation='relu',\n","                        input_shape=(150, 150, 3)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Flatten())\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer=optimizers.RMSprop(lr=1e-3), # learning rate\n","              metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x05_IGDOwku9","colab_type":"code","colab":{}},"source":["history = model.fit_generator(\n","      train_generator, # never see same image, for each epoch\n","      steps_per_epoch=100, # 1 x 60 samples for an epoch\n","      epochs=30,\n","      validation_data=validation_generator,\n","      validation_steps=50) # 1 (batch_size) x 15 = 15 validation samples"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mL3SmUQS1K_x","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'b', label='Training acc')\n","plt.plot(epochs, val_acc, 'r', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'b', label='Training loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zgXCSC_0Ycmu","colab_type":"code","colab":{}},"source":["from keras.preprocessing.image import ImageDataGenerator\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","test_generator = test_datagen.flow_from_directory(\n","        test_dir,\n","        target_size=(150, 150),\n","        batch_size=1,\n","        class_mode='binary')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jldeIdiEYdYA","colab_type":"code","colab":{}},"source":["# To get the 1st batch\n","for t_data_batch, t_labels_batch in test_generator:\n","    print('data batch shape:', t_data_batch.shape)\n","    print('labels batch shape:', t_labels_batch.shape)\n","    break # try this for loop without \"break\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KKY_WqUaYf6Y","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","#plt.figure(figsize=(10,10))\n","for i in range(20):\n","  plt.subplot(4,5,i+1)\n","  plt.tight_layout()\n","  plt.imshow(t_data_batch[i],interpolation='none')\n","  plt.title(\"Label: {}\".format(t_labels_batch[i]))\n","  plt.xticks([])\n","  plt.yticks([])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Gx6cnPOZ1T2","colab_type":"code","colab":{}},"source":["test_loss, test_acc = model.evaluate(test_generator)\n","print(\"Accuracy: \", test_acc)\n","print(\"Loss: \", test_loss)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9WFfoGoncuzk","colab_type":"text"},"source":["The reason finding a high accuracy is difficult is because there are not enough samples to generate an effective model. I also believe that since the non_circle pictures are the ones that are set to true, the model cannot find a pattern for a \"non-circle\" since there are multiple shapes among those pictures. If the circle pictures were set to true instead I believe it would be able to recognize the patterns more easily."]}]}